{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","import time\n","from datetime import datetime\n","import pandas as pd\n","from os import path\n","import yaml\n","from experiments import execute_command_on_server_and_clients, concat_dict\n","\n","from execo import SshProcess\n","from execo_g5k import oarsub, oardel, OarSubmission, get_current_oar_jobs, get_oar_job_nodes, get_oar_job_info, Deployment, deploy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["jobname=\"fl-measure\"\n","nodecount=3\n","walltime=\"03:00:00\"\n","resources_selection=\"-t exotic -p estats\"\n","site=\"toulouse\"\n","force_redeploy=False\n","environment_dsc_file='./images/fl_jetson_image.yaml'\n","\n","repository_dir = \"/home/mjay/FL-G5K-Test/\"\n","tmp_dir = \"/tmp/\"\n","jetson_sensor_monitor = f\"{repository_dir}/jetson_monitoring_energy.py\"\n","result_energy_file = \"energy.csv\"\n","log_file = \"logs.log\"\n","exp_csv = f\"{repository_dir}/outputs/experiment_summary.csv\""]},{"cell_type":"markdown","metadata":{},"source":["# Reserve a job and deploy the chosen environment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["jobs = get_current_oar_jobs()\n","jobid = None\n","waiting_jobs = []\n","while jobs:\n","    j, site = jobs.pop()\n","    info = get_oar_job_info(j, site)\n","    if info['name'] == jobname:\n","        if info['state'] == 'Running':\n","            jobid = j\n","            print(\"A {} job is already running, using it. jobid is {}\".format(jobname, jobid))\n","            break\n","        else:\n","            waiting_jobs.append(j)\n","if not jobid and not waiting_jobs:\n","    jobspec = OarSubmission(resources=\"/cluster=1/nodes={}\".format(nodecount), walltime=walltime,\n","                            additional_options=resources_selection, job_type=\"deploy\", name=jobname,\n","                            queue='testing')\n","    jobid, _ = oarsub([(jobspec, site)]).pop()\n","    print(\"New job submitted, jobid is {}\".format(jobid))\n","elif not jobid:\n","    print(\"One or more {} jobs exist ({}) but are not running.\\n\"\n","          \" Connect to the frontend to see what is happening, and/or run the cell again.\".format(\n","          jobname, \", \".join([str(j) for j in waiting_jobs])))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nodes = get_oar_job_nodes(jobid, site)\n","nodes.sort(key=lambda n: n.address)\n","nodes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["server=nodes[0]\n","clients=nodes[1:]\n","print(\"Server:{} \\n Clients: {}\".format(server,clients))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["deployment = Deployment(hosts=nodes, env_file=os.path.abspath(environment_dsc_file))\n","deploy_ok, deploy_failed = deploy(deployment, check_deployed_command=not force_redeploy,\n","                              stdout_handlers=[sys.stdout],\n","                              stderr_handlers=[sys.stderr])\n","print(\"Deployement status:\\n* ok: {}\\n* failed: {}\".format(deploy_ok, deploy_failed))"]},{"cell_type":"markdown","metadata":{},"source":["# Defining hyper parameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["exp_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","\n","result_folder = f\"{repository_dir}/outputs/{exp_datetime}/\"\n","!mkdir -p $result_folder \n","tmp_result_folder = f\"{tmp_dir}/{exp_datetime}/\"\n","\n","# Create hyperparameters folder\n","hyperparams = {}\n","hyperparams[\"result_folder\"]=result_folder\n","hyperparams[\"result_energy_file\"]=result_energy_file\n","hyperparams[\"log_file\"]=log_file\n","hyperparams[\"tmp_result_folder\"]=tmp_result_folder\n","hyperparams[\"exp_datetime\"]=exp_datetime\n","hyperparams[\"sleep_duration\"]=30\n","hyperparams[\"timestamps\"]={}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hyperparams[\"server\"] = server.address\n","for cid in range(len(clients)):\n","    hyperparams[f\"client_{cid}\"] = clients[cid].address"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_to_yaml = repository_dir + \"/config/config_file.yaml\"\n","with open(path_to_yaml) as yaml_file:\n","    yaml_contents = yaml.load(yaml_file, Loader=yaml.FullLoader)\n","hyperparams.update(yaml_contents)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hyperparams"]},{"cell_type":"markdown","metadata":{},"source":["# RUN EXPERIMENT"]},{"cell_type":"markdown","metadata":{},"source":["First step is to get to IP adress of the server so the clients can connect to it. To get it, we send a SshProcess to the server:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_host_ip(hostname):\n","    command = f\"hostname -I\"\n","    process = SshProcess(command, host=hostname)\n","    process.run()\n","    if process.ok:\n","        ip_address = process.stdout.strip()\n","        process.kill()\n","        return ip_address\n","    else:\n","        process.kill()\n","        return f\"Failed to get IP for {hostname}\"\n","\n","# Example usage\n","hostname = \"your_host\"\n","ip_address_full = get_host_ip(server)\n","ip_address = ip_address_full.split(\" \")[0]\n","print(f\"IP address for {hostname} is {ip_address}\")\n","hyperparams[\"comm\"][\"host\"]=ip_address"]},{"cell_type":"markdown","metadata":{},"source":["Now we define the SshProcess for the server and the clients, providing them with the hyper parameters of this experiment as defined in the previous section.\n","We first save results locally (in the /tmp/ folder) to reduce communication overhead. Results are copied back to the home dirs at the end of the training."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["command = f\"mkdir -p {tmp_result_folder}; echo -n > {tmp_result_folder}/logs.log\"\n","_ = execute_command_on_server_and_clients(nodes, command, f\"{repository_dir}/outputs/logs.log\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["command = f\"cd {repository_dir}; \\\n","    python3 main_server.py \\\n","    hydra.run.dir={tmp_result_folder} \\\n","    comm.host={ip_address}\"\n","print(command)\n","run_server = SshProcess(\n","    command, \n","    host=server, \n","    connection_params={'user':'root'}, \n","    stdout_handlers=[sys.stdout, f\"{repository_dir}/outputs/logs.log\"], \n","    stderr_handlers=[sys.stderr, f\"{repository_dir}/outputs/logs.log\"]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run_clients = []\n","for (host,cid) in zip(clients,range(len(clients))):\n","    command = f\"cd {repository_dir}; python3 client.py client.cid={cid} hydra.run.dir={tmp_result_folder} comm.host={ip_address}\"\n","    run_client=SshProcess(\n","        command, \n","        host=server, \n","        connection_params={'user':'root'},\n","        stdout_handlers=[sys.stdout, f\"{repository_dir}/outputs/logs.log\"], \n","        stderr_handlers=[sys.stderr, f\"{repository_dir}/outputs/logs.log\"])\n","    run_clients.append(run_client)"]},{"cell_type":"markdown","metadata":{},"source":["We can start the server, wait a few seconds so that it's ready before starting the clients."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# start the monitoring\n","command = f\"python3 {jetson_sensor_monitor} --log-dir {tmp_result_folder} --log-csv {result_energy_file}\"\n","jtop_processes = execute_command_on_server_and_clients(nodes, command, f\"{repository_dir}/outputs/logs.log\", background=True)\n","# sleep\n","hyperparams[\"timestamps\"][\"start_experiment_before_sleep\"]=time.time()\n","time.sleep(hyperparams[\"sleep_duration\"])\n","hyperparams[\"timestamps\"][\"start_experiment\"]=time.time()\n","# start the server and the clients\n","run_server.start()\n","time.sleep(5)\n","for run_client in run_clients:\n","    run_client.start()"]},{"cell_type":"markdown","metadata":{},"source":["The server will disconnect once the training is done. So we wait until the server SshProcess is done to process results and start another experiment."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# wait until the training is done\n","run_server.wait()\n","# kill the monitoring\n","for proc in jtop_processes:\n","    proc.kill()\n","# copy the logs back to the home repository\n","cp_command = f\"mkdir -p {result_folder}/server/; cp {tmp_result_folder}/* {result_folder}/server/\" #; rm -r {tmp_result_folder}\"\n","execute_command_on_server_and_clients([server], cp_command, f\"{repository_dir}/outputs/logs.log\")\n","for cid in range(len(clients)):\n","    cp_command = f\"mkdir -p {result_folder}/client_{cid}/; cp {tmp_result_folder}/* {result_folder}/client_{cid}/\" #; rm -r {tmp_result_folder}\"\n","    execute_command_on_server_and_clients([clients[cid]], cp_command, f\"{repository_dir}/outputs/logs.log\")\n","# save the timestamps and sleep to make sure the power goes down\n","hyperparams[\"timestamps\"][\"end_experiment\"]=time.time()\n","time.sleep(hyperparams[\"sleep_duration\"])\n","hyperparams[\"timestamps\"][\"end_experiment_after_sleep\"]=time.time()\n","# tmp_result_folder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hyperparams"]},{"cell_type":"markdown","metadata":{},"source":["# Process results and save it as csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def concat_dict(dict_list):\n","    new_dict = {}\n","    for d in dict_list:\n","        if isinstance(d, (dict)):\n","            new_dict.update(d)\n","    return new_dict\n","\n","res = concat_dict(hyperparams[\"defaults\"])\n","hyperparams[\"defaults\"] = res\n","\n","hyperparams_normalized = pd.json_normalize(hyperparams)\n","hyperparams_normalized.T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if path.exists(exp_csv):\n","    df = pd.read_csv(exp_csv)\n","    df = pd.concat([df, hyperparams_normalized], ignore_index=True)\n","else:\n","    df = pd.DataFrame(hyperparams_normalized)\n","df.to_csv(exp_csv, index=False)"]},{"cell_type":"markdown","metadata":{},"source":["If something went wrong:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run_server.kill()\n","[run_client.kill() for run_client in run_clients]"]},{"cell_type":"markdown","metadata":{},"source":["# Kill the job once all the experiments are done."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["oardel([(jobid,site)])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":2}
